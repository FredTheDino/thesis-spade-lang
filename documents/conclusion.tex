\chapter{Conclusion}
\label{cha:Conclusion}
Programming languages are complex things -- but they need to be complex to express complex and precise ideas. The wordlength inference outlined in this thesis shows a good way to extend the Spade hardware description language to more flexibly handle wordlengths. The wordlength inference works well with the current Damas-Hindley-Milner type checker and will allow language designers of the Spade language to make an active choice in how the Spade language should interact with wordlengths. There was no difference in the resource usages of spade programs before or after the wordlength inference from this paper was introduced. The authors believe that the real benefit from these changes will not come from performance gains -- though better performance might be possible in the future -- but the ''soft'' value of expressiveness and clearer programs. A possibility of clearer intent will make it possible for the Spade compiler to more clearly understand the programmer and might make more readable code and aid optimizations.


\section{How can interval arithmetic and affine arithmetic be used to implement wordlength inference?}
The most optimal way was to combine both interval arithmetic and affine arithmetic. Since both have different strengths and weaknesses the combination of the methods costs little in the way of resources but can in some instances give a lot smaller ranges which leads to smaller wordlengths. If this work is to be extended to support unsigned integers this combined method is bound to come in very handy. 

\section{How does wordlength inference and optimization affect the number of LUTs, DPS-blocks and memories for a circuit?}
This thesis clearly shows that this implementation of wordlength inference has no discernible effect on any resource usage metrics.

\section{Can wordlength inference be used to create more reusable code?}
The final state of the changes from this thesis made the compiler very finicky about wordlengths. The expressiveness in the typesystem has increased which has made it possible to express some types more clearly and making certain function types more expressive, making functions a more well integrated language construction -- aiding the reusability of code. Though it does not aid the resuability greatly the authors claim this is an improvement no matter how modest it is. Future work could easily expand on this.

\section{Future Work}
The implementation used in this thesis opens the door for an even more sophisticated approach where sub-expressions could be evaluated by either AA or IA. One can consider an evaluation tree where all possible combinations of AA and IA are used -- though this tree might be too large to easily evaluate in practice, a technique like this would give theoretically optimal wordlengths for expressions. Removing the requirement that variables are opaque could also make the wordlength inference a lot better and might also be an interesting point of research in the future.

Since the Spade compiler now understands expressions and the values the expressions can be evaluated to it is trivial to check for expressions that evaluate to a constant. A constant expression is almost always a programmer error, but even when it isn't it should be replaced with the constant for clearer readability. This range analysis can also be used to trim dead code even before the code generation, and then warn about unreachable paths.

Since the compiler now reasons about ranges of integer values unsigned integer optimizations should be possible to do in a multitude of places. Maybe even automatically generating code that uses unsigned integers if the code never goes below 0. But this can of course be taken a step further, and all expressions could be re-written by the compiler to avoid going below 0. We can trivially rewrite the expressions inside the compiler since integer arithmetic is a well behaved ring (unlike floating point numbers). This could lead to improved resource usage in some places. Maybe it could even be possible to shift the representation of numbers inside the compiler.

Some of the typing and inference rules need to be updated to make the language work well with e.g. Constants passed to functions. Looking into these kinds of rules could make the language clearer and more expressive -- pairing it with a usability study could be very enlightening.

There are also more advanced wordlength inference methods. There are alternatives to AA which might prove useful -- like ME-gPC. Maybe it is possible to track every possible integer value an expression can take, and allowing these holes in the expressions would make it possible to give even more precise guidance and help.

Maybe it could be possible to pair the Spade-language with more complex formal verification methods, and allow formal verification of circuits in the language directly. The language for the generics could also be extended to support this formal verification step, so that constraints for functions that require certain ranges based on the input can be wordlength inferred and typechecked more seamlessly. For an example envision the type signature \verb+fn double<#A, #B>(a: int<#A..#B>) -> int<2*#A, 2*#B>+.

This work has added a separate wordlength inference module in addition to the typechecking, but it might still be very beneficial if they are one and the same -- and thus looking into more complex type systems or reworking the current typesystem might still be a good idea, this is another way to make functioncalls less opaque.

As a personal note, I'd find it very interesting to add an interpreter to the Spade-language such that designs could be simulated without the need of an FPGA, this could also aid different kind of verification and might be an alternative to a more powerful typesystem.
