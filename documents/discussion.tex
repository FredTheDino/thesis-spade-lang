\chapter{Discussion}
\label{cha:Discussion}
After a thorough evaluation of the different suggested methods of implementing wordlength inference the implementations and their evaluations are discussed. Much of the discussion focuses on the final implementation since it produced the best results and was subject to the most evaluations.

\section{Results}
The Spade compiler was successfully changed to support ranges and more sophisticated wordlength inference. These changes were not able to be completed to the degree that they could be fully integrated into the mainline compiler -- but most of the technical problems have been solved. What remains are language design decisions and glue code.

The table in Table \ref{fig:CompareThings} shows that the AAIA method results in the thightest ranges and the smallest wordlengths. That a combination of the techniques is superior is hardly surprising since IA handles multiplication better for expressions with a 0-lower bound while AA can handle subtractions of the same constants. A combination is bound to work better than any of them in isolation. Of special consideration is how IA handles $0$ a lot better, since ranges bound by 0 are still bound by $0$ even after multiplication, this is not the case for AA. This begs the question if there is a better method that would give even tighter ranges, and may be a suitable future work.

The internal changes to the Spade compiler typeinference caused a sea of troubles to appear. If the Spade project want to integrate these changes fully care needs to be taken when implementing and updating language features like memories. There is also a lot of work needed to port all the tests for the Spade language. All of these are fairly manual changes but may require a lot of time. To fully integrate these changes a series of language design decisions would also need to be taken, for example how constants passed to functions should type check or the example in Figure \ref{fig:BetterProgram} which require extra help when inferring some type variables -- this is believed to come from function calls being opaque to the wordlength inference

The opaqueness of functioncalls is a large problem in the current implementation, and perhaps the simplest way of solving is probably to move the wordlength inference into the typeinference module. The information that is needed is nowhere to be found in the wordlength inference stages of the compiler and should either be rebuilt or preferably given with the type checking state. But it may also be a sign that the method described in Section \ref{sec:Forth} might have been an even better choice -- and if the typechecking were to be changed to function on ranges which was also required to change in Section \ref{sec:Seven2} there may be a better implementation that easily fits into the typechecking step of the Spade compiler.

There was no discernible difference between the programs between synthesis and PNR runs with any of the wordlength inference methods. The table in Table \ref{fig:SpadeCompilations50Table} motivates this -- even though the averages might suggest subtly against it. This means there is no real difference in LUTs or memories used when using the wordlength inference in this thesis. It may be claimed that the difference in variance is an improvement, it may also be due to random noise from the compiler since synthesis and PNR has undeterministic behavior. Figure \ref{fig:SMDoutput} and Figure \ref{fig:FIRoutput} support the claim of little difference. Though it is worth noting that something may be different in the compilation process since both of these figures show no noise. It may be the case that these improvements only aid the more sophisticated optimization steps in the synthesis and PNR-phase, and this could also explain why the improvement negligible. This may signal an error in the experiments and that the Spade implementation with the range-based wordlength inference may have a bug which causes incorrect codegeneration, unfortunately there was no access to hardware to verify this implementation on. This is a major limitation of this study but does not deter from the wordlength inference presented or the conclusions reached.

The solver for wordlengths that is described in Section \ref{sec:Seven} is very simple -- and as thus may not produce the best results possible. The solver does not handle solving equations with unknowns on both sides of the constraint, and variables being opaque to the AA method makes it produce worse results in some cases though most of the experiments in this work are simple enough to not make a huge difference. The inference algorithm could be modified to substitute entire expressions when evaluating using the AA method and it would probably produce slightly better results -- though the types would still need to be reduced to ranges.

In the Spade language wordlength inference is now more flexible, and allows propagation of ranges between functions. That wordlength information can be sent in more detail between different parts of the program means that developers need fewer assumptions of how the code works. Less assumptions result in fewer sign-extensions and truncation operations on integer expressions. The power of AA also makes it beneficial to write larger expressions instead of splitting them up in smaller chunks with placeholder variables -- since variables are always reduced to ranges by the wordlength inference algorithm for variable types.

Unfortunately the representation of integer values inside of the Spade compiler is ranges, which hinders some of the AA inference. Since each variable in Spade has a singular range paired with it the information of the sub-expressions is discarded: the information AA uses to function well is lost. For the AA wordlength inference method each variable is opaque and cannot be inspected into. Since variables are opaque it is better to inline expressions without the use of variables since the wordlength inference code can reason a lot better about those expressions.

\subsection{Limitations in the Spade Compiler}
The implementation offered in this thesis can have quite confusing error messages. This is due to the type checker discarding information of where type information came from -- and the typeinference module is left looking at the expressions and types given by the type checker. Changing what the Spade compiler stores from the typechecking phase would require a fair bit of plumbing but still nothing hugely complicated to implement. For later stages in the compiler it would be preferable to make some changes in the compiler to support:
\begin{itemize}
  \item A list of spans that have been unified to give a type for an expression -- this would make it possible to point to the type signatures from stages that do e.g. constant folding or wordlength inference.
  \item A full list of the constraints and requirements for a type -- currently the compiler tosses these constraints and requirements when they are deemed satisfied, this discards the sources of facts that both the type checker and wordlength inference module would find helpful.
  \item It would be great if \verb+Requirement+ and \verb+ConstraintExpr+ could be one construction -- it would aid interoperability and remove some technical debt in the type checker.
  \item It would also be beneficial if each entity in the Spade program could be compiled as far as possible -- so if type checking for one function of the program fails the wordlength could still be checked for an entity that is not related.
\end{itemize}

There are also profits in the area of usability of the Spade language -- removing truncation operations from the Spade code can make the code a lot more readable. Since most of the truncations and sign extensions are required by the very simple wordlength inference method present before this thesis it is probably the single largest contribution that has been made. The change in wordlength inference makes the Spade compiler more flexible and makes it possible to remove a lot of the truncation and extension operations.

\section{Method}
The method does not focus directly on wordlength inference but focuses more on the software development side, which is in stark contrast with the research questions. This might however show more fault in the usage of research questions than this thesis. The author do believe the code changes that came from this thesis to be among the best possible for the given time. The fumbling evaluation of alternative implementations gives a basis for that argument. It is however possible for such an implementation to have been found by thinking very carefully and very hard -- though theoretically sound ideas often crumble in agony when faced with the sledgehammer that is reality. Especially if those theories are drawn from inexperience.

From software development it is well known that an iterative approach to software development often yields the best results in a fixed amount of time. The idea of using some form of agile development methodology seems to have been a sound idea.

It is also frustrating to leave the compiler in a state where most of the work is \textit{almost} done. As stated earlier in the thesis -- it is possible that some of the changes that need to be done are in fact harder than they appear. But programming work is well known to be hard to plan. This thesis does however leave a good base to work further on the compiler. It may also be for the better that these other changes are made by someone on the core Spade compiler team. Though this thesis has been a collaboration with the Spade compiler team, communication is always lossy, and details are bound to be forgotten. Hopefully these changes are well documented enough to be of use and be able to be well integrated into the language.

\section{The Work in a Wider Context}
More sophisticated wordlength inference in Spade unfortunately has little effect on the planet or the current war in Ukraine that is currently raging. But this contribution need not be discarded as useless. A slight improvement in efficiency for hardware designs can have cascading effects on how cheap it is to produce custom circuits. The cheaper cost can of course lead to an increased production which is what has already happened to goods such as computers and cars. Hardware description languages and FPGAs is used heavily in the weapons industry and thus code created in this thesis may contribute to more raging wars. However, it is essential to recognize that war is a double-edged sword -- it can both preserve and condemn -- yet its inherent nature remains one of destruction.

Hopefully hardware designers will rejoice over this work.
